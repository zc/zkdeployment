Agents
======

    >>> setup_logging()

Agents are responsible for watching a ZooKeeper tree and making local
updates to reflect what's in a tree.

Agents can determine their own host identifier.  The host identifier
comes from /etc/zmh/pxemac.

Low-level machinery
-------------------

Create an agent:

    >>> import mock
    >>> import zc.zkdeployment.agent
    >>> patcher = mock.patch('subprocess.Popen',
    ...     **{'side_effect': zc.zkdeployment.tests.subprocess_popen})
    >>> _ = patcher.start()
    >>> agent = zc.zkdeployment.agent.Agent()
    INFO Agent starting, cluster 1, host 1

The agent knows its host identifier:

    >>> agent.host_identifier
    '424242424242'

An agent may also have a role.  We'll say more about that later. This
one doesn't have one:

    >>> agent.role

An agent can tell its current version number, as recorded in the zookeeper
tree.

    >>> import zc.zk
    >>> zk = zc.zk.ZK('zookeeper:2181')
    >>> zk.print_tree()
    /cust
      /someapp
        /cms : z4m
          version = u'1.0.0'
          /deploy
            /424242424242
        /monitor : z4mmonitor
          version = u'1.1.0'
          /deploy
            /424242424242
    /cust2
      /someapp
        /cms : z4m
          version = u'1.0.0'
          /deploy
            /424242424242
    /hosts
      version = 1
      /424242424242
        name = u'host42'
        version = 1

    >>> agent.version == zk.get_properties('/hosts/424242424242')['version']
    True

An agent can also tell the cluster version number, which all hosts in the
cluster should aspire to.

    >>> agent.cluster_version == zk.get_properties('/hosts')['version']
    True

When an agent notices a change, it first collects a collection of all
of the deployments:

    >>> sorted(agent.get_deployments())
    [Deployment(app=u'z4m', subtype=None, version=u'1.0.0', rpm_name=u'z4m',
                path=u'/cust/someapp/cms', n=0),
     Deployment(app=u'z4m', subtype=None, version=u'1.0.0', rpm_name=u'z4m',
                path=u'/cust2/someapp/cms', n=0),
     Deployment(app=u'z4mmonitor', subtype=None, version=u'1.1.0',
                rpm_name=u'z4mmonitor',
                path=u'/cust/someapp/monitor', n=0)]

This is compared with the installed applications on its host:

    >>> sorted(agent.get_installed_deployments())
    [UnversionedDeployment(app=u'z4m', rpm_name=u'z4m',
                           path='/cust/someapp/cms', n=0),
     UnversionedDeployment(app=u'z4m', rpm_name=u'z4m',
                           path='/cust2/someapp/cms', n=0),
     UnversionedDeployment(app=u'z4mmonitor', rpm_name=u'z4mmonitor',
                           path='/cust/someapp/monitor', n=0)]

Basic updates
-------------

OK, we've demonstrated some of the pieces.  Now let's try making a
change.  Let change the application parts of the tree::

  /cust
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242

  /cust2
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

We've removed a monitor installation.

When we update the version number of the hosts node, the agent is
going to uninstall the missing monitor installation and run the
installation script for everything that's installed:

    >>> hosts_properties = zk.properties('/hosts')
    >>> import time
    >>> version = 1
    >>> wait = .1 if ZooKeeper else .5
    >>> def set_hosts_version(value):
    ...     hosts_properties.update(version=value)
    ...     time.sleep(wait)
    >>> def bump_version(inc=1, value=None):
    ...     global version
    ...     version += inc
    ...     set_hosts_version(version)
    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 2
    INFO /opt/z4mmonitor/bin/zookeeper-deploy -u /cust/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy -u /cust/someapp/monitor 0
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO /opt/z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO yum -y remove z4mmonitor
    yum -y remove z4mmonitor
    INFO Done deploying version 2

'424242424242' now reports itself as being on version 2 for all of its
deployments.

    >>> zk.print_tree('/hosts')
    /hosts
      version = 2
      /424242424242
        name = u'host42'
        version = 2

If we add a deployment, it will notice this, too, and run the appropriate
installation::

  /cust
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242

  /cust2
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

Here, we're installing a new monitor for cust2

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 3
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install z4mmonitor-1.1.0
    yum -y install z4mmonitor-1.1.0
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 3

If we remove a deployment, but there are other deployments using
the same software, it will not uninstall the RPM.  Here, we'll
remove a z4m deployment from cust2, but leave one for cust::

  /cust
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242

  /cust2
    /someapp
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

When we update the tree, the deployment gets removed, but the
RPM is not uninstalled.

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 4
    INFO /opt/z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 0
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 4

Multiple deployments of the same node
-------------------------------------

You can also specify multiple deployments of a given type by using the
``n`` property.  Here, we'll configure 3 z4m instances for cust2::

  /cust
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242

  /cust2
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242
              n = 3
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

Now, when we update the version, the 3 deployments will be installed.

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 5
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 1
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 1
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 2
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 2
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 5

If we reduce the number::

  /cust2
    /someapp
      /cms : z4m
         version = '1.0.0'
         /deploy
            /424242424242
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

the extra instances will be removed:

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 6
    INFO /opt/z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 1
    z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 1
    INFO /opt/z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 2
    z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 2
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 6

Software versions
-----------------

If we update z4m to a newer version::

  /cust
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /424242424242

  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /424242424242
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

yum will install the newer version before updating the deployment.

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 7
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install z4m-2.0.0
    yum -y install z4m-2.0.0
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 7

If our zookeeper tree has conflicting versions for a given app::

  /cust
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /424242424242

  /cust2
    /someapp
      /cms : z4m
         version = '3.0.0'
         /deploy
            /424242424242
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

We will get an error.

    >>> bump_version() # doctest: +ELLIPSIS
    INFO ============================================================
    INFO Deploying version 8
    ERROR deploying
    Traceback (most recent call last):
    ...
    ValueError: Inconsistent versions for z4m. u'3.0.0' != u'2.0.0'
    CRITICAL FAILED deploying version 8

We realize that z4m needs to be installed differently.  We can't
update z4m installations in place, because the application reads
installed files at run-time.  We switch to creating a separate RPM
package for each version. When we update to version 4, the version is
in the node type, rather than in a property::

  /cust
    /someapp
      /cms : z4m-4.0.0
         /deploy
            /424242424242

  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /424242424242
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

Note that now we can have different instances use different versions.
``cust`` is upgraded to ``4.0.0``, but ``cust2`` is still running
``3.0.0``.

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 9
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install z4m-4.0.0
    yum -y install z4m-4.0.0
    INFO yum -q list installed z4m-4.0.0
    yum -q list installed z4m-4.0.0
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m-4.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m-4.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 9

If we update the version of z4m again, it will install the new RPM,
reconfigure, and then uninstall the old one, since no deployments are
using it any more::

  /cust
    /someapp
      /cms : z4m-5.0.0
         /deploy
            /424242424242

  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /424242424242
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /424242424242

.. -> tree

    >>> zk.import_tree(tree, trim=True)

The old rpm gets removed:

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 10
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install z4m-5.0.0
    yum -y install z4m-5.0.0
    INFO yum -q list installed z4m-5.0.0
    yum -q list installed z4m-5.0.0
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO yum -y remove z4m-4.0.0
    yum -y remove z4m-4.0.0
    INFO Done deploying version 10

Host names
----------

In the examples above, we've used host ids.  We can also use host
names::

  /cust
    /someapp
      /cms : z4m-5.0.0
         /deploy
            /host42

  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /host42
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /host42

.. -> tree

    >>> zk.import_tree(tree, trim=True)

In the tree above, the we've replaced the host id with the host name.

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 11
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -q list installed z4m-5.0.0
    yum -q list installed z4m-5.0.0
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 11

If we try to deploy to a host with the id 353535353535::

  /cust
    /someapp
      /cms : z4m-5.0.0
         /deploy
            /host42

  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /host42
              n = 1
            /353535353535
              n = 4
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /host42

.. -> tree

    >>> zk.import_tree(tree, trim=True)

Our host agent will ignore the deployment::

    >>> bump_version()
    INFO ============================================================
    INFO Deploying version 12
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -q list installed z4m-5.0.0
    yum -q list installed z4m-5.0.0
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 12

If you try to deploy the same deployment to a host identifier and
its associated human-readable hostname::

  /cust
    /someapp
      /cms : z4m-5.0.0
         /deploy
            /host42

  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /host42
              n = 1
            /424242424242
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /host42

.. -> tree

    >>> zk.import_tree(tree, trim=True)

You'll get an error::

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 13
    ERROR deploying
    Traceback (most recent call last):
    ...
    ValueError: Conflicting deployments for /cust2/someapp/cms.
    Can't deploy to host42 and 424242424242.
    CRITICAL FAILED deploying version 13

We fix the tree::

  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /host42
              n = 1
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /host42

.. -> tree

    >>> zk.import_tree(tree, trim=True)

And we're good::

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 14
    INFO yum -q list installed z4m
    yum -q list installed z4m
    INFO yum -q list installed z4m-5.0.0
    yum -q list installed z4m-5.0.0
    INFO yum -q list installed z4mmonitor
    yum -q list installed z4mmonitor
    INFO /opt/z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    z4m-5.0.0/bin/zookeeper-deploy /cust/someapp/cms 0
    INFO /opt/z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy /cust2/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy /cust2/someapp/monitor 0
    INFO Done deploying version 14

Roles
-----

A host can be configured by role, instead of by host id (or name).
If a host has a role, then it will only be configured by role.  This
ensures that host of a given role are configured identically.

Suppose we decide that host42 is going to be a cache server.  Let's
add a cache server config::

  /cust
    /someapp
      /cms : z4m-5.0.0
         /deploy
            /host42
      /cache : squid
        version = '2.0'
        /deploy
          /cache
  /cust2
    /someapp
      /cms : z4m
         version = '2.0.0'
         /deploy
            /host42
              n = 1
      /cache : squid
        version = '2.0'
        /deploy
          /cache
      /monitor : z4mmonitor
         version = '1.1.0'
         /deploy
            /host42

.. -> tree

    >>> zk.import_tree(tree, trim=True)

and give the host a role:

    >>> import os
    >>> with open('etc/zim/role', 'w') as f:
    ...     f.write('cache\n')

The agent reads the role at startup.  We'll close the agent and
restart it:

    >>> agent.close()
    >>> agent = zc.zkdeployment.agent.Agent()
    INFO Agent starting, cluster 14, host 14
    >>> agent.role
    'cache'

When we update the tree version, the agent will report an error,
because it has both role-based and host-based configurations:

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 15
    ERROR deploying
    Traceback (most recent call last):
    ...
    ValueError: Found a host-based deployment at
    /cust/someapp/cms/deploy/host42 but the host has a role, cache.
    CRITICAL FAILED deploying version ...

If we deploy to the role, though::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)

The deployment goes through, and the host reconfigures itself as a cache.

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 16
    INFO /opt/z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 0
    z4m/bin/zookeeper-deploy -u /cust2/someapp/cms 0
    INFO /opt/z4m-5.0.0/bin/zookeeper-deploy -u /cust/someapp/cms 0
    z4m-5.0.0/bin/zookeeper-deploy -u /cust/someapp/cms 0
    INFO /opt/z4mmonitor/bin/zookeeper-deploy -u /cust2/someapp/monitor 0
    z4mmonitor/bin/zookeeper-deploy -u /cust2/someapp/monitor 0
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install squid-2.0
    yum -y install squid-2.0
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO yum -y remove z4m
    yum -y remove z4m
    INFO yum -y remove z4m-5.0.0
    yum -y remove z4m-5.0.0
    INFO yum -y remove z4mmonitor
    yum -y remove z4mmonitor
    INFO Done deploying version 16

Verbose mode
------------

If we set the "verbose" flag on the agent, it will log even successful command
output.

    >>> agent.verbose = True
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 17
    INFO yum -q list installed squid
    yum -q list installed squid
    Installed Packages
    squid 	2.0-1 	installed
    INFO SUCCESS
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO SUCCESS
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO SUCCESS
    INFO Done deploying version 17

    >>> agent.verbose = False

Run once
--------

We can also create an agent that will do a single deployment and then quit.

This can be useful when manually running deployments.

Let's create a new agent, and see that it deploys:

    >>> agent.close()
    >>> agent = zc.zkdeployment.agent.Agent(run_once=True)
    INFO Agent starting, cluster 17, host 17

If we bump the version, the agent won't do a deployment:

    >>> bump_version()

Let's switch back to an active agent:

    >>> agent = zc.zkdeployment.agent.Agent(); time.sleep(wait)
    INFO Agent starting, cluster 18, host 17
    INFO ============================================================
    INFO Deploying version 18
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO Done deploying version 18


Error handling
--------------

When we get errors, when calling yum or deploy scripts, the yum or
script output is logged::

  /cust
    /someapp
      /cache : squid
        version = 'bad'
        /deploy
          /cache
  /cust2
    /someapp
      /cache : squid
        version = 'bad'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)

Here, the squid version is bad:

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 19
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install squid-bad
    yum -y install squid-bad
    Error: Couldn't find package squid-bad
    ERROR FAILURE
    ERROR deploying
    Traceback (most recent call last):
    ...
    RuntimeError: Command failed: yum -y install squid-bad
    CRITICAL FAILED deploying version 19

In addition, the cluster version is set to None, which will make other
agents stop in their tracks to avoid propegating a problem, and the
error is recorded in the host's node:

    >>> zk.print_tree("/hosts")
    /hosts
      version = None
      /424242424242
        error = u'Command failed: yum -y install squid-bad'
        name = u'host42'
        role = u'cache'
        version = 18

Now, we'll install a cranky app::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
      /acrank : cranky
        version = '1.0'
        /deploy
          /cache
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache


.. -> tree

    >>> zk.import_tree(tree, trim=True)

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 20
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install cranky-1.0
    yum -y install cranky-1.0
    INFO yum -q list installed cranky
    yum -q list installed cranky
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/cranky/bin/zookeeper-deploy /cust/someapp/acrank 0
    cranky/bin/zookeeper-deploy /cust/someapp/acrank 0
    waaaaaaaaaaaa
    ERROR FAILURE
    ERROR deploying
    Traceback (most recent call last):
    ...
    RuntimeError: Command failed:
        /opt/cranky/bin/zookeeper-deploy /cust/someapp/acrank 0
    CRITICAL FAILED deploying version 20

And, again, the is set to None and the error is recorded:

    >>> zk.print_tree("/hosts")
    /hosts
      version = None
      /424242424242
        error = u'Command failed: /opt/cranky/bin/zookeeper-deploy ...'
        name = u'host42'
        role = u'cache'
        version = 18

Let's remove the cranky app::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)

Everything's fixed now.

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 21
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO yum -y remove cranky
    yum -y remove cranky
    INFO Done deploying version 21

And the error is cleared from the host's node:

    >>> zk.print_tree("/hosts")
    /hosts
      version = 21
      /424242424242
        name = u'host42'
        role = u'cache'
        version = 21

We're done with this agent.

    >>> agent.close()

Deregistration (ephemeral host nodes)
-------------------------------------

When the agent closes, it's host node goes away:

    >>> zk.print_tree()
    /agent-locks
      /cust,someapp,acrank
      /cust,someapp,cache
      /cust,someapp,cms
      /cust2,someapp,cache
      /cust2,someapp,cms
      /cust2,someapp,monitor
    /cust
      /someapp
        /cache : squid
          version = u'2.0'
          /deploy
            /cache
    /cust2
      /someapp
        /cache : squid
          version = u'2.0'
          /deploy
            /cache
    /hosts
      version = 21

But the version is saved in /etc/zim/host_version:

    >>> with open('etc/zim/host_version') as f:
    ...     print f.read()
    21

When we restart the agent, it will load it's version and update if it
needs to.

Let's set the cluster version to something different::

    /hosts
      version = 19

.. -> tree

Note that versions don't have to be increasing. Thert don't really
have to be numbers. :)

    >>> zk.import_tree(tree, trim=True)

The agent updates itself to version 19.

    >>> agent = zc.zkdeployment.agent.Agent(); time.sleep(wait)
    INFO Agent starting, cluster 19, host 21
    INFO ============================================================
    INFO Deploying version 19
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO Done deploying version 19

    >>> agent.version
    19

Version Control
---------------

The agent can also accept an VCS url as a version.  In this case,
it will do a subversion checkout of the location and build out the software::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
      /rewriter : pywrite
        version = 'svn+ssh://svn.zope.com/repos/main/pywrite/trunk'
        /deploy
          /cache
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)
    >>> zc.zkdeployment.agent.register()

When the software is deployed, it will get built out correctly.

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 22
    INFO svn co svn+ssh://svn.zope.com/repos/main/pywrite/trunk /opt/pywrite
    INFO Build pywrite (svn+ssh://svn.zope.com/repos/main/pywrite/trunk)
    INFO /opt/pywrite/stage-build
    /opt/pywrite/stage-build
    INFO chmod -R a+rX .
    chmod -R a+rX .
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/pywrite/bin/zookeeper-deploy /cust/someapp/rewriter 0
    pywrite/bin/zookeeper-deploy /cust/someapp/rewriter 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO Done deploying version 22

On update, it will check out the software again, pulling in any new changes.

    >>> zk.import_tree(tree, trim=True)
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 23
    INFO svn info /opt/pywrite
    INFO svn co svn+ssh://svn.zope.com/repos/main/pywrite/trunk /opt/pywrite
    INFO Build pywrite (svn+ssh://svn.zope.com/repos/main/pywrite/trunk)
    INFO /opt/pywrite/stage-build
    /opt/pywrite/stage-build
    INFO chmod -R a+rX .
    chmod -R a+rX .
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/pywrite/bin/zookeeper-deploy /cust/someapp/rewriter 0
    pywrite/bin/zookeeper-deploy /cust/someapp/rewriter 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO Done deploying version 23

When the svn-deployed software is uninstalled, it will get removed::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
      /rewriter : pywrite
        version = 'svn+ssh://svn.zope.com/repos/main/pywrite/trunk'
        /deploy
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)

Now the software will get removed:

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 24
    INFO /opt/pywrite/bin/zookeeper-deploy -u /cust/someapp/rewriter 0
    pywrite/bin/zookeeper-deploy -u /cust/someapp/rewriter 0
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO Removing checkout pywrite
    INFO Done deploying version 24

If we switch from VCS to rpm, the VCS directory will be removed first::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
      /rewriter : pywrite
        version = 'svn+ssh://svn.zope.com/repos/main/pywrite/trunk'
        /deploy
          /cache
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 25
    INFO svn co svn+ssh://svn.zope.com/repos/main/pywrite/trunk /opt/pywrite
    ...

::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
      /rewriter : pywrite
        version = '3.0'
        /deploy
          /cache
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 26
    INFO Removing checkout pywrite
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install pywrite-3.0
    ...

Now, remove the deployment again::

  /cust
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache
      /rewriter : pywrite
        version = 'svn+ssh://svn.zope.com/repos/main/pywrite/trunk'
        /deploy
  /cust2
    /someapp
      /cache : squid
        version = '2.0'
        /deploy
          /cache

.. -> tree



    >>> zk.import_tree(tree, trim=True)
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 27
    ...


Handling missing /etc/APP directories
=====================================

Sometimes, especially when installing stage builds, there are failures
that prevent creation of an /etc directory after installing an RPM.
To illustrate, we'll create a bogus application in /opt:

    >>> os.makedirs(os.path.join('opt', 'badapp', '.svn'))
    >>> os.makedirs(os.path.join('opt', 'badapp', 'bin'))
    >>> open(os.path.join('opt', 'badapp', 'bin', 'zookeeper-deploy'),
    ...      'w').close()
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 28
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO Removing checkout badapp
    INFO Done deploying version 28

Handling legacy zk databases:

    >>> agent.close()

We used to use non-ephemeral nodes.  If the agent starts and sees a
node for itself, it will read the version and convert the node to an
emphemeral node::

    /hosts
      version = 1

.. -> tree

    >>> zk.import_tree(tree, trim=True)
    >>> agent = zc.zkdeployment.agent.Agent(); time.sleep(wait)
    INFO Agent starting, cluster 1, host 28
    INFO ============================================================
    INFO Deploying version 1
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO /opt/squid/bin/zookeeper-deploy /cust/someapp/cache 0
    squid/bin/zookeeper-deploy /cust/someapp/cache 0
    INFO /opt/squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy /cust2/someapp/cache 0
    INFO Done deploying version 1

    >>> zk.print_tree('/hosts')
    /hosts
      version = 1
      /424242424242
        name = u'host42'
        role = u'cache'
        version = 1

    >>> agent.close()
    >>> zk.print_tree('/hosts')
    /hosts
      version = 1


Don't trust yum
===============

Yum is stupid.

Among the ways that yum is stupid is that when it fails to find a
package, including a new version, it happily exits with an exit code
of zero, so we need to check after the install that it really happened.

::

  /cust
    /someapp
      /cache : squid
        version = '666'
        /deploy
          /cache

.. -> tree


    >>> zk.import_tree(tree, trim=True)
    >>> zk.delete_recursive('/cust2') # XXX Need better way to delete customers
    >>> agent = zc.zkdeployment.agent.Agent(); time.sleep(wait)
    INFO Agent starting, cluster 1, host 1
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 29
    INFO /opt/squid/bin/zookeeper-deploy -u /cust2/someapp/cache 0
    squid/bin/zookeeper-deploy -u /cust2/someapp/cache 0
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install squid-666
    yum -y install squid-666
    INFO yum -q list installed squid
    yum -q list installed squid
    INFO yum -y downgrade squid-666
    yum -y downgrade squid-666
    INFO yum -q list installed squid
    yum -q list installed squid
    ERROR deploying
    Traceback (most recent call last):
    ...
    SystemError: Failed to install squid-666 (installed: 2.0)
    CRITICAL FAILED deploying version 29

::

  /cust
    /someapp
      /cache : varnish
        version = '666'
        /deploy
          /cache

.. -> tree


    >>> zk.import_tree(tree, trim=True)
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 30
    INFO /opt/squid/bin/zookeeper-deploy -u /cust/someapp/cache 0
    squid/bin/zookeeper-deploy -u /cust/someapp/cache 0
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install varnish-666
    yum -y install varnish-666
    ERROR deploying
    Traceback (most recent call last):
    ...
    SystemError: Failed to install varnish-666 (installed: None)
    CRITICAL FAILED deploying version 30


Sub-tyoes (alternate recipes)
-----------------------------

You can specify subtypes::

  /cust
    /someapp
      /cache : varnish special
        version = '1'
        /deploy
          /cache

.. -> tree

    >>> zk.import_tree(tree, trim=True)

This causes a -r option to be passed to the zookeeper-deploy script.

    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 31
    INFO yum -y clean all
    yum -y clean all
    INFO yum -y install varnish-1
    yum -y install varnish-1
    INFO yum -q list installed varnish
    yum -q list installed varnish
    INFO /opt/varnish/bin/zookeeper-deploy -r special /cust/someapp/cache 0
    varnish/bin/zookeeper-deploy -r special /cust/someapp/cache 0
    INFO yum -y remove squid
    yum -y remove squid
    INFO Done deploying version 31

Let's make sure uninstalling works too::

  /cust
    /someapp

.. -> tree

    >>> zk.import_tree(tree, trim=True)
    >>> bump_version() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
    INFO ============================================================
    INFO Deploying version 32
    INFO /opt/varnish/bin/zookeeper-deploy -u /cust/someapp/cache 0
    varnish/bin/zookeeper-deploy -u /cust/someapp/cache 0
    INFO yum -y remove varnish
    yum -y remove varnish
    INFO Done deploying version 32

String versions
===============

Versions can be strings:

    >>> set_hosts_version('string-version-a')
    INFO ============================================================
    INFO Deploying version string-version-a
    INFO DEBUG: got deployments
    INFO DEBUG: remove old deployments
    INFO DEBUG: update software
    INFO Done deploying version string-version-a

Fail safe error handling
========================

When an error occurs, the cluster version is set to None. A this
point, agents are unwilling to deploy until a human sorts the problem
out and sets the cluster version to a number or a string.

    >>> set_hosts_version(None)

Deployments will also be suppressed if the cluster version is False:

    >>> set_hosts_version(False)

Agents won't do deployments if the version is false, but the VCS sync
tool *will* still sync VCS with the ZooKeeper tree if the version is
False.  When you've solved a deployment problem by updating VCS, you
can cause the update to be propagated on the next sync by setting the
``/hosts`` version to False.

.. tear down

    >>> patcher.stop()


.. [#testroot] To make testing easier, the applications in this
   framework respect the environment variable TEST_ROOT when looking
   for and creating files. In the test set up we set this to the
   current directiory, which is itself a test directory.
